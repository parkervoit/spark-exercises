{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "- The name of the column should be language\n",
    "- View the schema of the dataframe\n",
    "- Output the shape of the dataframe\n",
    "- Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas df\n",
    "fav_lang_df = pd.DataFrame(\n",
    "        {\n",
    "            \"languages\": ['python','sql','go','c','java','scala']\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sql</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>scala</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  languages\n",
       "0    python\n",
       "1       sql\n",
       "2        go\n",
       "3         c\n",
       "4      java\n",
       "5     scala"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify it worked\n",
    "fav_lang_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put into spark df\n",
    "df = spark.createDataFrame(fav_lang_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.describe of DataFrame[languages: string]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view schema\n",
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1)\n"
     ]
    }
   ],
   "source": [
    "# output df shape\n",
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|languages|\n",
      "+---------+\n",
      "|   python|\n",
      "|      sql|\n",
      "|       go|\n",
      "|        c|\n",
      "|     java|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# output of first 5 rows\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the mpg dataset as a spark dataframe.\n",
    "\n",
    "    1. Create 1 column of output that contains a message like the one below for each vehicle:\n",
    "        ```The 1999 audi a4 has a 4 cylinder engine.```\n",
    "\n",
    "    1. Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg = spark.createDataFrame(data(\"mpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|     model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+----------+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|        a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|        a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|        a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|        a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|        a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "|        audi|        a4|  2.8|1999|  6|manual(m5)|  f| 18| 26|  p|compact|\n",
      "|        audi|        a4|  3.1|2008|  6|  auto(av)|  f| 18| 27|  p|compact|\n",
      "|        audi|a4 quattro|  1.8|1999|  4|manual(m5)|  4| 18| 26|  p|compact|\n",
      "|        audi|a4 quattro|  1.8|1999|  4|  auto(l5)|  4| 16| 25|  p|compact|\n",
      "|        audi|a4 quattro|  2.0|2008|  4|manual(m6)|  4| 20| 28|  p|compact|\n",
      "+------------+----------+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|       Make/model/PU|\n",
      "+--------------------+\n",
      "|The 1999 audi a4 ...|\n",
      "|The 1999 audi a4 ...|\n",
      "|The 2008 audi a4 ...|\n",
      "|The 2008 audi a4 ...|\n",
      "|The 1999 audi a4 ...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(concat(lit('The '), \n",
    "                 mpg.year, \n",
    "                 lit(' '), \n",
    "                 mpg.manufacturer, \n",
    "                 lit(' '), \n",
    "                 mpg.model, \n",
    "                 lit(' has a '), \n",
    "                 mpg.cyl, \n",
    "                 lit(' cylinder engine.')\n",
    "                ).alias('Make/model/PU')\n",
    "         ).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+-----+----+---+--------+---+---+---+---+-------+\n",
      "|manufacturer|          model|displ|year|cyl|   trans|drv|cty|hwy| fl|  class|\n",
      "+------------+---------------+-----+----+---+--------+---+---+---+---+-------+\n",
      "|       dodge|    caravan 2wd|  3.8|2008|  6|auto(l6)|  f| 16| 23|  r|minivan|\n",
      "|       dodge|    caravan 2wd|  4.0|2008|  6|auto(l6)|  f| 16| 23|  r|minivan|\n",
      "|        ford| expedition 2wd|  5.4|2008|  8|auto(l6)|  r| 12| 18|  r|    suv|\n",
      "|        ford|   explorer 4wd|  4.6|2008|  8|auto(l6)|  4| 13| 19|  r|    suv|\n",
      "|     lincoln|  navigator 2wd|  5.4|2008|  8|auto(l6)|  r| 12| 18|  r|    suv|\n",
      "|     mercury|mountaineer 4wd|  4.6|2008|  8|auto(l6)|  4| 13| 19|  r|    suv|\n",
      "+------------+---------------+-----+----+---+--------+---+---+---+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.where(mpg[\"trans\"] == \"auto(l6)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+\n",
      "|     trans|regexp_extract|\n",
      "+----------+--------------+\n",
      "|  auto(l5)|          auto|\n",
      "|manual(m5)|        manual|\n",
      "|manual(m6)|        manual|\n",
      "|  auto(av)|          auto|\n",
      "|  auto(l5)|          auto|\n",
      "|manual(m5)|        manual|\n",
      "|  auto(av)|          auto|\n",
      "|manual(m5)|        manual|\n",
      "|  auto(l5)|          auto|\n",
      "|manual(m6)|        manual|\n",
      "|  auto(s6)|          auto|\n",
      "|  auto(l5)|          auto|\n",
      "|manual(m5)|        manual|\n",
      "|  auto(s6)|          auto|\n",
      "|manual(m6)|        manual|\n",
      "|  auto(l5)|          auto|\n",
      "|  auto(s6)|          auto|\n",
      "|  auto(s6)|          auto|\n",
      "|  auto(l4)|          auto|\n",
      "|  auto(l4)|          auto|\n",
      "+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(\n",
    "    'trans',\n",
    "    regexp_extract(\"trans\", r\"^(\\w+)\\(\", 1).alias(\"regexp_extract\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the tips dataset as a spark dataframe.\n",
    "\n",
    "    1. What percentage of observations are smokers?\n",
    "    1. Create a column that contains the tip percentage\n",
    "    1. Calculate the average tip percentage for each combination of sex and smoker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = spark.createDataFrame(data('tips'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.createOrReplaceTempView('tips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''SELECT * FROM tips''').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|         smoker_pct|\n",
      "+-------------------+\n",
      "|0.38114754098360654|\n",
      "+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''SELECT((SELECT COUNT(smoker)\n",
    "FROM tips\n",
    "WHERE smoker = \"Yes\") / (SELECT COUNT(smoker)\n",
    "FROM tips)) as smoker_pct\n",
    "FROM tips''').show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|            tip_pct|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|0.18623962040332148|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|0.22805017103762829|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|0.11607142857142858|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|0.13031914893617022|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2| 0.2185385656292287|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2| 0.1665043816942551|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|0.14180374361883155|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|0.10181582360570687|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|0.16277807921866522|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|0.20364126770060686|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|0.18164967562557924|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3| 0.1616650532429816|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|0.22774708410067526|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|0.20624631703005306|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|0.16222760290556903|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "SELECT *, (tip / total_bill) as tip_pct\n",
    "FROM tips\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = spark.sql(\n",
    "                    \"\"\"\n",
    "                SELECT *, (tip / total_bill) as tip_pct\n",
    "                FROM tips\n",
    "                    \"\"\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+-------------------+\n",
      "|   sex|                No|                Yes|\n",
      "+------+------------------+-------------------+\n",
      "|Female|0.1569209707691836|0.18215035269941032|\n",
      "|  Male|0.1606687151291298|0.15277117520248512|\n",
      "+------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.groupby('sex').pivot('smoker').mean('tip_pct').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use the seattle weather dataset referenced in the lesson to answer the questions below.\n",
    "\n",
    "    1. Convert the temperatures to fahrenheit.\n",
    "    1. Which month has the most rain, on average?\n",
    "    1. Which year was the windiest?\n",
    "    1. What is the most frequent type of weather in January?\n",
    "    1. What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "    1. What percentage of days were rainy in q3 of 2015?\n",
    "    1. For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vega_datasets import data\n",
    "\n",
    "weather = data.seattle_weather().assign(date=lambda df: df.date.astype(str))\n",
    "weather = spark.createDataFrame(weather)\n",
    "weather.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weather.withColumn('f_temp_max', ((weather.temp_max.cast('decimal') * 9 / 5) + 32))\\\n",
    "                 .withColumn('f_temp_min', ((weather.temp_min.cast('decimal') * 9 / 5) + 32))\\\n",
    "                 .drop('temp_min','temp_max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----+-------+----------+----------+\n",
      "|      date|precipitation|wind|weather|f_temp_max|f_temp_min|\n",
      "+----------+-------------+----+-------+----------+----------+\n",
      "|2012-01-01|          0.0| 4.7|drizzle| 55.400000| 41.000000|\n",
      "|2012-01-02|         10.9| 4.5|   rain| 51.800000| 37.400000|\n",
      "|2012-01-03|          0.8| 2.3|   rain| 53.600000| 44.600000|\n",
      "|2012-01-04|         20.3| 4.7|   rain| 53.600000| 42.800000|\n",
      "|2012-01-05|          1.3| 6.1|   rain| 48.200000| 37.400000|\n",
      "|2012-01-06|          2.5| 2.2|   rain| 39.200000| 35.600000|\n",
      "|2012-01-07|          0.0| 2.3|   rain| 44.600000| 37.400000|\n",
      "|2012-01-08|          0.0| 2.0|    sun| 50.000000| 37.400000|\n",
      "|2012-01-09|          4.3| 3.4|   rain| 48.200000| 41.000000|\n",
      "|2012-01-10|          1.0| 3.4|   rain| 42.800000| 33.800000|\n",
      "|2012-01-11|          0.0| 5.1|    sun| 42.800000| 30.200000|\n",
      "|2012-01-12|          0.0| 1.9|    sun| 42.800000| 28.400000|\n",
      "|2012-01-13|          0.0| 1.3|    sun| 41.000000| 26.600000|\n",
      "|2012-01-14|          4.1| 5.3|   snow| 39.200000| 33.800000|\n",
      "|2012-01-15|          5.3| 3.2|   snow| 33.800000| 26.600000|\n",
      "|2012-01-16|          2.5| 5.0|   snow| 35.600000| 26.600000|\n",
      "|2012-01-17|          8.1| 5.6|   snow| 37.400000| 32.000000|\n",
      "|2012-01-18|         19.8| 5.0|   snow| 32.000000| 26.600000|\n",
      "|2012-01-19|         15.2| 1.6|   snow| 30.200000| 26.600000|\n",
      "|2012-01-20|         13.5| 2.3|   snow| 44.600000| 30.200000|\n",
      "+----------+-------------+----+-------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|month|         avg_rain|\n",
      "+-----+-----------------+\n",
      "|   11|5.354166666666667|\n",
      "+-----+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.withColumn('month', month('date'))\\\n",
    "    .groupBy('month')\\\n",
    "    .agg(mean('precipitation').alias('avg_rain'))\\\n",
    "    .sort(desc('avg_rain'))\\\n",
    "    .show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+\n",
      "|year|         avg_wind|\n",
      "+----+-----------------+\n",
      "|2012|3.400819672131148|\n",
      "+----+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.withColumn('year', year('date'))\\\n",
    "    .groupBy('year')\\\n",
    "    .agg(mean('wind').alias('avg_wind'))\\\n",
    "    .sort(desc('avg_wind'))\\\n",
    "    .show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+---+----+----+---+\n",
      "|month_weather|drizzle|fog|rain|snow|sun|\n",
      "+-------------+-------+---+----+----+---+\n",
      "|            1|     10| 38|  35|   8| 33|\n",
      "+-------------+-------+---+----+----+---+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.withColumn('month', month('date'))\\\n",
    "     .crosstab('month', 'weather').sort(asc('month_weather')).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "| avg_max_temp| avg_min_temp|\n",
      "+-------------+-------------+\n",
      "|80.3230769231|57.4423076923|\n",
      "+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.filter(((year('date') == 2013) | (year('date') == 2014)) & (month('date') == 7) & (weather.weather == 'sun'))\\\n",
    "    .agg(mean(weather.f_temp_max).alias('avg_max_temp'), mean(weather.f_temp_min).alias('avg_min_temp'))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "quart = weather.withColumn(\"quarter\", quarter(\"date\")).withColumn(\"year\", year(\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "quart_rain = quart.filter(expr('year == 2015 AND quarter == 3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021739130434782608"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quart_rain.where(quart_rain.weather == 'rain').count() / quart_rain.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = weather.withColumn('year', year('date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48360655737704916"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(years.filter(expr('year == 2012')).filter(expr('precipitation > 0')).count()) / (years.filter(expr('year == 2012')).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41643835616438357"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(years.filter(expr('year == 2013')).filter(expr('precipitation > 0')).count()) / (years.filter(expr('year == 2013')).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.410958904109589"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(years.filter(expr('year == 2014')).filter(expr('precipitation > 0')).count()) / (years.filter(expr('year == 2014')).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39452054794520547"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(years.filter(expr('year == 2015')).filter(expr('precipitation > 0')).count()) / (years.filter(expr('year == 2015')).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+\n",
      "|year|          avg(rain)|\n",
      "+----+-------------------+\n",
      "|2015|0.39452054794520547|\n",
      "|2013|0.41643835616438357|\n",
      "|2014|  0.410958904109589|\n",
      "|2012|0.48360655737704916|\n",
      "+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# instructor solution\n",
    "(\n",
    "    weather.withColumn('year', year('date'))\n",
    "    .select(when(col('precipitation') > 0, 1).otherwise(0).alias('rain'), 'year')\n",
    "    .groupby('year')\n",
    "    .agg(mean('rain'))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
